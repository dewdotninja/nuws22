{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee326b5",
   "metadata": {},
   "source": [
    "### 2.3.7 สร้างโมเดลโดยไลบรารี TF\n",
    "\n",
    "ในตัวอย่างที่ผ่านมาเราใช้ภาษาไพธอนเขียนโครงสร้างภายในของ DNN ทั้งในส่วนแพร่กระจายด้านหน้าและย้อนหลังเพื่อให้เข้าใจถึงแผนภาพการคำนวณอย่างชัดแจ้ง \n",
    "ในทางปฏิบัติเมื่อโมเดลมีความซับซ้อนมากขึ้นจะนิยมใช้ไลบรารีช่วยในการสร้างโมเดล ซึ่ง TF เป็นหนึ่งในไลบรารีที่มีคำสั่งสนับสนุนการสร้างโมเดลตั้งแต่ DNN \n",
    "ธรรมดาจนถึงโมเดลการเรียนรู้เชิงลึกประเภทอื่น ในหัวข้อนี้จะสาธิตการสร้างโมเดล DNN สำหรับจำแนกประเภท\n",
    "\n",
    "**ตัวอย่าง 2.5**\n",
    "\n",
    "ในตัวอย่างนี้เราจะศึกษาการจำแนกประเภทของภาพสุนัขและแมวจากข้อมูลที่ดาวน์โหลดได้จาก \n",
    "\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=54765 \n",
    "    \n",
    "นำไฟล์ไปไว้ใน /datasets และแตกไฟล์ออกเป็นไดเรคทอรีย่อย /kagglecatsanddogs_3367a/Petimages ซึ่งเป็นค่าโดยปริยายของไฟล์ \n",
    "kagglecatsanddogs_3367a.zip ที่ดาวน์โหลดมา หากผู้อ่านเปลี่ยนชื่อของไดเรคทอรีก็เพียงแก้โค้ดในตัวอย่างนี้ให้สอดคล้องกัน  \n",
    "นำเข้าไลบรารีที่ใช้ในการจัดการไฟล์\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf59255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f2fbb",
   "metadata": {},
   "source": [
    "ตรวจสอบจำนวนภาพทั้งหมดของแมวและสุนัข"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('datasets/kagglecatsanddogs_3367a/Petimages/Cat/')))\n",
    "print(len(os.listdir('datasets/kagglecatsanddogs_3367a/Petimages/Dog/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0938875",
   "metadata": {},
   "source": [
    "สร้างไดเรคทอรีย่อยเพื่อเก็บภาพสำหรับการฝึกและทดสอบดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('datasets/cats-v-dogs')\n",
    "    os.mkdir('datasets/cats-v-dogs/training')\n",
    "    os.mkdir('datasets/cats-v-dogs/testing')\n",
    "    os.mkdir('datasets/cats-v-dogs/training/cats')\n",
    "    os.mkdir('datasets/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('datasets/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('datasets/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37245217",
   "metadata": {},
   "source": [
    "เขียนฟังก์ชัน split_data() เพื่อแยกจำนวนภาพสำหรับฝึกและทดสอบตามอัตราส่วนที่กำหนดและใส่ไฟล์ลงในไดเรคทอรีย่อยที่สร้างไว้\n",
    "นอกจากนั้นฟังก์ชันยังสามารถขจัดภาพที่ใช้งานไม่ได้ คือมีขนาดไฟล์เป็นศูนย์ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[:testing_length]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a03866",
   "metadata": {},
   "source": [
    "เรียกฟังก์ชันโดยกำหนด 90% ของจำนวนไฟล์สำหรับการฝึกและ 10% สำหรับทดสอบ เอาต์พุตที่ได้จากการรันฟังก์ชัน split_data() \n",
    "คือไฟล์ที่ถูกขจัดออกเนื่องจากมีขนาดเป็นศูนย์ พบว่ามีจำนวนไฟล์เสียสำหรับภาพสุนัขและแมวอย่างละ 1 ไฟล์ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_SOURCE_DIR = \"datasets/kagglecatsanddogs_3367a/Petimages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"datasets/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"datasets/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"datasets/kagglecatsanddogs_3367a/Petimages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"datasets/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"datasets/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697f321",
   "metadata": {},
   "source": [
    "ตรวจสอบจำนวนไฟล์สำหรับฝึกและทดสอบของภาพสุนัขและแมว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training files (Cats) = ' + str(len(os.listdir('datasets/cats-v-dogs/training/cats/'))))\n",
    "print('Number of training files (Dogs) = ' +str(len(os.listdir('datasets/cats-v-dogs/training/dogs/'))))\n",
    "print('Number of testing files (Cats) = ' +str(len(os.listdir('datasets/cats-v-dogs/testing/cats/'))))\n",
    "print('Number of testing files (Dogs) = ' +str(len(os.listdir('datasets/cats-v-dogs/testing/dogs/'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d2d4a",
   "metadata": {},
   "source": [
    "หากตรวจสอบข้อมูลภาพเหล่านี้ในไดเรคทอรีจะพบว่ามีขนาดความกว้างความยาวที่แตกต่างกัน  \n",
    "ดังนั้นก่อนที่จะดำเนินการกับภาพหล่านี้จะต้องมีการประมวลผลเบื้องต้นเพื่อทำให้ข้อมูลมีความเหมาะสมกับการฝึก เช่นปรับมาตราส่วน ขนาดภาพ\n",
    "ในกรณีที่ไฟล์ภาพถูกเก็บอยู่ในไดเรคทอรีดังเช่นในตัวอย่างนี้ เราสามารถใช้ฟังก์ชันเสริมคือ ImageDataGenerator() เข้าช่วย \n",
    "ซึ่งฟังก์ชันสามารถปรับแต่งภาพได้มากกว่านี้เช่นการหมุน ขยาย เฉือน ฯลฯ เรียกว่าการแต่งเติมภาพ (image augmentation)\n",
    "แต่ในตัวอย่างนี้ต้องการเพียงลดค่าของแต่ละพิกเซลให้อยู่ในช่วง 0 - 1 และปรับขนาดภาพเป็น 150 x 150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad94f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"datasets/cats-v-dogs/training/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "VALIDATION_DIR = \"datasets/cats-v-dogs/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=100,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(150, 150))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691b285",
   "metadata": {},
   "source": [
    "การสร้างโมเดล DNN โดยไลบรารี TF เริ่มจากนำเข้าไลบรารีที่ต้องการใช้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9152bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84ec0a",
   "metadata": {},
   "source": [
    "ทดลองสร้างโมเดล 3 ชั้นแฝง มีจำนวนเซลล์แต่ละชั้นเท่ากับ 128, 64, 1 \n",
    "ฟังก์ชันกระตุ้นของชั้นแฝงแบบ ReLU และของชั้นเอาต์พุตแบบซิกมอยด์ เขียนเป็นโค้ดได้ดังนี้ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae695f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(150, 150, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c95f3",
   "metadata": {},
   "source": [
    "โดยใช้ Sequential() ในการสร้างโมเดลและต้องใช้ชั้นแรกเป็น Flatten() \n",
    "ที่มีรูปแบบอินพุตตรงกับขนาดภาพที่สร้างโดย ImageDataGenerator() \n",
    "\n",
    "ใช้เมธอด model.compile() กำหนดตัวหาค่าเหมาะที่สุดแบบ SGD ฟังก์ชันสูญเสีย 'binary_crossentropy'\n",
    "และใช้ความแม่นยำเป็นตัววัด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15877f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(learning_rate=0.01),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7718a1",
   "metadata": {},
   "source": [
    "ฝึกโมเดลจำนวน 15 รอบ โดยคืนค่าข้อมูลที่เป็นประวัติการฝึกในตัวแปรดิกชันนารี history (เซลล์นี้อาจใช้เวลานานในการรัน)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=15,verbose=1,validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e2162",
   "metadata": {},
   "source": [
    "xห่ลังจากการฝึกเสร็จสิ้น เราสามารถเข้าถึงข้อมูลใน history เพื่อพล็อตค่าความแม่นยำและการสูญเสียเทียบกับจำนวนรอบการฝึก \n",
    "ดังแสดงในรููปที่ 2.23 และ 2.24 ตามลำดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylim([0.5,0.7])\n",
    "plt.legend([\"Training\",\"Validation\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3972b",
   "metadata": {},
   "source": [
    "รูปที่ 2.23 ค่าความแม่นยำจากข้อมูลการฝึกและข้อมูลทดสอบเทียบกับจำนวนรอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa68c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.ylim([0.6,0.7])\n",
    "plt.legend([\"Training\",\"Validation\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38a72a",
   "metadata": {},
   "source": [
    "รูปที่ 2.24 ค่าจากฟังก์ชันสูญเสียเทียบกับจำนวนรอบ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807ce1e",
   "metadata": {},
   "source": [
    "จากความแม่นยำที่ได้พบว่ามีค่าอยู่ประมาณไม่เกิน 70% ซึ่งเป็นผลที่ไม่น่าพอใจนักสำหรับการจำแนกภาพแมวและสุนัข \n",
    "ข้อด้อยของการใช้ DNN ในการจำแนกภาพคือไม่สามารถเรียนรู้ข้อมูลเชิงพื้นที่ (spatial information) \n",
    "ซึ่งเป็นองค์ประกอบภาพที่มีความสำคัญ เมื่อเราได้ศึกษาโมเดลแบบ CNN จะพบว่าสามารถจำแนกภาพด้วยความแม่นยำกว่า\n",
    "DNN มาก\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdd587",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/thumbnail?id=13bzT7Rmy3bzvE7TiS0yfQo94kpxMuipF\" alt=\"dewninja\"/>\n",
    "</p>\n",
    "<div align=\"center\">dew.ninja 2022</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d7b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
